{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Student Name: Ashwathy Ashokan\n",
        "\n",
        "Student ID: C0935859\n",
        "\n",
        "Subject: Big Data Framework 01\n",
        "\n",
        "Assignment: RDDs and Spark SQL **bold text**"
      ],
      "metadata": {
        "id": "yKYvffTy4VOl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Section A: RDD Operations"
      ],
      "metadata": {
        "id": "iB-F_vtm5YOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1: RDD Creation and Basic Operations"
      ],
      "metadata": {
        "id": "RZzPppWE5fMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"RDD Assignment\").getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "\n",
        "# Load sales.csv\n",
        "sales_rdd = sc.textFile(\"sales.csv\")\n",
        "header = sales_rdd.first()\n",
        "sales_data = sales_rdd.filter(lambda row: row != header)\n",
        "\n",
        "# Display first 5 rows\n",
        "print(sales_data.take(5))\n",
        "\n",
        "# Count transactions\n",
        "print(f\"Total transactions: {sales_data.count()}\")\n",
        "\n",
        "# Extract (product_id, price)\n",
        "prod_price = sales_data.map(lambda x: (x.split(\",\")[1], float(x.split(\",\")[4])))\n",
        "print(prod_price.take(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGjl7sYU5f8Q",
        "outputId": "91ed3e94-ce33-4c5f-deeb-9d8bd48f0602"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1,P1,U1,1,10.0', '2,P2,U2,2,20.0', '3,P3,U3,3,15.0', '4,P4,U1,2,30.0', '5,P2,U2,1,25.0']\n",
            "Total transactions: 20\n",
            "[('P1', 10.0), ('P2', 20.0), ('P3', 15.0), ('P4', 30.0), ('P2', 25.0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2: Transformations and Actions"
      ],
      "metadata": {
        "id": "lA5Gmsl35jGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming columns: transaction_id, product_id, user_id, quantity, price\n",
        "\n",
        "# Total revenue\n",
        "revenue_rdd = sales_data.map(lambda x: float(x.split(\",\")[3]) * float(x.split(\",\")[4]))\n",
        "print(f\"Total revenue: {revenue_rdd.sum()}\")\n",
        "\n",
        "# Unique products sold\n",
        "product_ids = sales_data.map(lambda x: x.split(\",\")[1]).distinct()\n",
        "print(f\"Unique products: {product_ids.count()}\")\n",
        "\n",
        "# Filter where quantity > 1\n",
        "filtered = sales_data.filter(lambda x: int(x.split(\",\")[3]) > 1)\n",
        "print(filtered.take(5))\n",
        "\n",
        "# (product_id, revenue)\n",
        "prod_rev = sales_data.map(lambda x: (x.split(\",\")[1], float(x.split(\",\")[3]) * float(x.split(\",\")[4])))\n",
        "total_rev_per_prod = prod_rev.reduceByKey(lambda x, y: x + y)\n",
        "print(total_rev_per_prod.take(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7DxYnVj5sw0",
        "outputId": "81fd51b1-fb4f-48ff-978f-084ce938f51f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total revenue: 780.0\n",
            "Unique products: 4\n",
            "['2,P2,U2,2,20.0', '3,P3,U3,3,15.0', '4,P4,U1,2,30.0', '6,P1,U3,4,10.0', '7,P4,U2,2,35.0']\n",
            "[('P1', 100.0), ('P2', 275.0), ('P3', 135.0), ('P4', 270.0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3: Working with Multiple RDDs"
      ],
      "metadata": {
        "id": "0e0bPTgQ5xNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "products_rdd = sc.textFile(\"products.csv\").filter(lambda x: x != \"product_id,product_name,category\")\n",
        "users_rdd = sc.textFile(\"users.csv\").filter(lambda x: x != \"user_id,user_name,location\")\n",
        "\n",
        "# Keyed by product_id\n",
        "products_kv = products_rdd.map(lambda x: (x.split(\",\")[0], x.split(\",\")[1]))  # product_id, product_name\n",
        "sales_kv = sales_data.map(lambda x: (x.split(\",\")[1], (x.split(\",\")[0], float(x.split(\",\")[3]) * float(x.split(\",\")[4]))))\n",
        "\n",
        "# Join sales with products\n",
        "joined_sales = sales_kv.join(products_kv)\n",
        "result = joined_sales.map(lambda x: (x[1][0][0], x[1][1], x[1][0][1]))  # transaction_id, product_name, revenue\n",
        "\n",
        "# Now join with users\n",
        "users_kv = users_rdd.map(lambda x: (x.split(\",\")[0], (x.split(\",\")[1], x.split(\",\")[2])))\n",
        "sales_users_kv = sales_data.map(lambda x: (x.split(\",\")[2], (x.split(\",\")[0], float(x.split(\",\")[3]) * float(x.split(\",\")[4]))))\n",
        "\n",
        "final_join = sales_users_kv.join(users_kv).map(lambda x: (x[1][0][0], x[1][1][0], x[1][1][1], x[1][0][1]))  # transaction_id, user_name, location, revenue\n"
      ],
      "metadata": {
        "id": "DEkiy8Is5z0P"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4: Advanced RDD Operations"
      ],
      "metadata": {
        "id": "I5oVXWcn52u8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 5 products by revenue\n",
        "top5_products = total_rev_per_prod.takeOrdered(5, key=lambda x: -x[1])\n",
        "print(\"Top 5 products by revenue:\", top5_products)\n",
        "\n",
        "# Total spending per user\n",
        "user_spend = sales_data.map(lambda x: (x.split(\",\")[2], float(x.split(\",\")[3]) * float(x.split(\",\")[4])))\n",
        "spend_by_user = user_spend.reduceByKey(lambda x, y: x + y)\n",
        "print(spend_by_user.take(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-Q4bWys56M9",
        "outputId": "d4e2aab6-cafa-414e-a11a-b511187fa76a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 products by revenue: [('P2', 275.0), ('P4', 270.0), ('P3', 135.0), ('P1', 100.0)]\n",
            "[('U3', 300.0), ('U1', 220.0), ('U2', 260.0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Section B: DataFrames and SQL"
      ],
      "metadata": {
        "id": "Ak6Vq0e958t7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5: DataFrame Creation and Exploration"
      ],
      "metadata": {
        "id": "RO4ELjI16BaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_df = spark.read.csv(\"sales.csv\", header=True, inferSchema=True)\n",
        "products_df = spark.read.csv(\"products.csv\", header=True, inferSchema=True)\n",
        "users_df = spark.read.csv(\"users.csv\", header=True, inferSchema=True)\n",
        "\n",
        "sales_df.printSchema()\n",
        "products_df.printSchema()\n",
        "users_df.printSchema()\n",
        "\n",
        "sales_df.show(5)\n",
        "products_df.show(5)\n",
        "users_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rG2vOv9l6KE9",
        "outputId": "0ab18a3d-f143-4244-e4f1-12d6258fff54"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- transaction_id: integer (nullable = true)\n",
            " |-- product_id: string (nullable = true)\n",
            " |-- user_id: string (nullable = true)\n",
            " |-- quantity: integer (nullable = true)\n",
            " |-- price: double (nullable = true)\n",
            "\n",
            "root\n",
            " |-- product_id: string (nullable = true)\n",
            " |-- product_name: string (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            "\n",
            "root\n",
            " |-- user_id: string (nullable = true)\n",
            " |-- user_name: string (nullable = true)\n",
            " |-- location: string (nullable = true)\n",
            "\n",
            "+--------------+----------+-------+--------+-----+\n",
            "|transaction_id|product_id|user_id|quantity|price|\n",
            "+--------------+----------+-------+--------+-----+\n",
            "|             1|        P1|     U1|       1| 10.0|\n",
            "|             2|        P2|     U2|       2| 20.0|\n",
            "|             3|        P3|     U3|       3| 15.0|\n",
            "|             4|        P4|     U1|       2| 30.0|\n",
            "|             5|        P2|     U2|       1| 25.0|\n",
            "+--------------+----------+-------+--------+-----+\n",
            "only showing top 5 rows\n",
            "\n",
            "+----------+------------+----------+\n",
            "|product_id|product_name|  category|\n",
            "+----------+------------+----------+\n",
            "|        P1|         Pen|Stationery|\n",
            "|        P2|    Notebook|Stationery|\n",
            "|        P3|      Pencil|Stationery|\n",
            "|        P4|      Marker|Stationery|\n",
            "+----------+------------+----------+\n",
            "\n",
            "+-------+---------+----------+\n",
            "|user_id|user_name|  location|\n",
            "+-------+---------+----------+\n",
            "|     U1|    Alice|  New York|\n",
            "|     U2|      Bob|California|\n",
            "|     U3|  Charlie|     Texas|\n",
            "+-------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6: SQL Queries"
      ],
      "metadata": {
        "id": "XkM79OiQ6L0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_df.createOrReplaceTempView(\"sales\")\n",
        "products_df.createOrReplaceTempView(\"products\")\n",
        "users_df.createOrReplaceTempView(\"users\")\n",
        "\n",
        "# Total revenue\n",
        "spark.sql(\"SELECT SUM(quantity * price) AS total_revenue FROM sales\").show()\n",
        "\n",
        "# Top 5 users\n",
        "spark.sql(\"\"\"\n",
        "    SELECT u.user_name, SUM(s.quantity * s.price) AS total_spent\n",
        "    FROM sales s JOIN users u ON s.user_id = u.user_id\n",
        "    GROUP BY u.user_name\n",
        "    ORDER BY total_spent DESC\n",
        "    LIMIT 5\n",
        "\"\"\").show()\n",
        "\n",
        "# Count of products sold by category\n",
        "spark.sql(\"\"\"\n",
        "    SELECT p.category, COUNT(s.product_id) AS product_sold\n",
        "    FROM sales s JOIN products p ON s.product_id = p.product_id\n",
        "    GROUP BY p.category\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMglyX2i6WPe",
        "outputId": "93ba883f-5a81-449d-ef0a-01df1705868c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+\n",
            "|total_revenue|\n",
            "+-------------+\n",
            "|        780.0|\n",
            "+-------------+\n",
            "\n",
            "+---------+-----------+\n",
            "|user_name|total_spent|\n",
            "+---------+-----------+\n",
            "|  Charlie|      300.0|\n",
            "|      Bob|      260.0|\n",
            "|    Alice|      220.0|\n",
            "+---------+-----------+\n",
            "\n",
            "+----------+------------+\n",
            "|  category|product_sold|\n",
            "+----------+------------+\n",
            "|Stationery|          20|\n",
            "+----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7: Joins and Aggregations"
      ],
      "metadata": {
        "id": "X4qAR0tA6YZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enriched_df = sales_df.join(users_df, \"user_id\").join(products_df, \"product_id\")\n",
        "enriched_df = enriched_df.withColumn(\"revenue\", enriched_df[\"quantity\"] * enriched_df[\"price\"])\n",
        "enriched_df.select(\"transaction_id\", \"user_name\", \"location\", \"product_name\", \"category\", \"quantity\", \"price\", \"revenue\").show(5)\n",
        "\n",
        "# Revenue per location\n",
        "enriched_df.groupBy(\"location\").sum(\"revenue\").show()\n",
        "\n",
        "# Avg quantity per category\n",
        "enriched_df.groupBy(\"category\").avg(\"quantity\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OktMSez36bCB",
        "outputId": "438b9032-d2a8-47d0-f84a-cb50d3beed54"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+---------+----------+------------+----------+--------+-----+-------+\n",
            "|transaction_id|user_name|  location|product_name|  category|quantity|price|revenue|\n",
            "+--------------+---------+----------+------------+----------+--------+-----+-------+\n",
            "|             1|    Alice|  New York|         Pen|Stationery|       1| 10.0|   10.0|\n",
            "|             2|      Bob|California|    Notebook|Stationery|       2| 20.0|   40.0|\n",
            "|             3|  Charlie|     Texas|      Pencil|Stationery|       3| 15.0|   45.0|\n",
            "|             4|    Alice|  New York|      Marker|Stationery|       2| 30.0|   60.0|\n",
            "|             5|      Bob|California|    Notebook|Stationery|       1| 25.0|   25.0|\n",
            "+--------------+---------+----------+------------+----------+--------+-----+-------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+----------+------------+\n",
            "|  location|sum(revenue)|\n",
            "+----------+------------+\n",
            "|     Texas|       300.0|\n",
            "|California|       260.0|\n",
            "|  New York|       220.0|\n",
            "+----------+------------+\n",
            "\n",
            "+----------+-------------+\n",
            "|  category|avg(quantity)|\n",
            "+----------+-------------+\n",
            "|Stationery|         1.95|\n",
            "+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8: Window Functions and Ranking"
      ],
      "metadata": {
        "id": "NqUhtuOo6en7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import rank, sum as _sum\n",
        "\n",
        "# Rank users by spending within location\n",
        "user_spend_df = enriched_df.groupBy(\"user_id\", \"user_name\", \"location\").agg(_sum(\"revenue\").alias(\"total_spent\"))\n",
        "windowSpec = Window.partitionBy(\"location\").orderBy(user_spend_df[\"total_spent\"].desc())\n",
        "ranked_users = user_spend_df.withColumn(\"rank\", rank().over(windowSpec))\n",
        "ranked_users.show()\n",
        "\n",
        "# Top product per category by revenue\n",
        "prod_rev_df = enriched_df.groupBy(\"category\", \"product_name\").agg(_sum(\"revenue\").alias(\"total_revenue\"))\n",
        "windowSpec2 = Window.partitionBy(\"category\").orderBy(prod_rev_df[\"total_revenue\"].desc())\n",
        "top_products = prod_rev_df.withColumn(\"rank\", rank().over(windowSpec2)).filter(\"rank = 1\")\n",
        "top_products.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHT73z9e6huQ",
        "outputId": "33781c10-7d45-4d64-8e03-b4f64963ed2f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+----------+-----------+----+\n",
            "|user_id|user_name|  location|total_spent|rank|\n",
            "+-------+---------+----------+-----------+----+\n",
            "|     U2|      Bob|California|      260.0|   1|\n",
            "|     U1|    Alice|  New York|      220.0|   1|\n",
            "|     U3|  Charlie|     Texas|      300.0|   1|\n",
            "+-------+---------+----------+-----------+----+\n",
            "\n",
            "+----------+------------+-------------+----+\n",
            "|  category|product_name|total_revenue|rank|\n",
            "+----------+------------+-------------+----+\n",
            "|Stationery|    Notebook|        275.0|   1|\n",
            "+----------+------------+-------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bonus: Caching and Parquet"
      ],
      "metadata": {
        "id": "WMCdouxg6jk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cache enriched df\n",
        "enriched_df.cache()\n",
        "\n",
        "# Write to Parquet\n",
        "enriched_df.write.mode(\"overwrite\").parquet(\"output/enriched_data.parquet\")\n",
        "\n",
        "# Read back\n",
        "parquet_df = spark.read.parquet(\"output/enriched_data.parquet\")\n",
        "parquet_df.groupBy(\"location\").sum(\"revenue\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOQjRfk16oWW",
        "outputId": "893c5523-8eb2-46a8-f9d8-f3cfa49be49f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+\n",
            "|  location|sum(revenue)|\n",
            "+----------+------------+\n",
            "|     Texas|       300.0|\n",
            "|California|       260.0|\n",
            "|  New York|       220.0|\n",
            "+----------+------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}